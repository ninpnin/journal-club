<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <title>journal-club</title>
    <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
    override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
    font-size: inherit;
    width: 0.8em;
    margin: 0 0.8em 0.2em -1.6em;
    vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    </style>
    <link rel="stylesheet" href="pandoc.css" />
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <h1>UU Stats and ML Journal Club</h1>
    <p>This is the Machine learning and Statistics Journal Club. We gather
    roughly every third week.</p>
    <h2>Upcoming meetings</h2>
    <h3>2024-01-18 – Deep Learning-based Propensity Scores</h3>
    <figure>
      <p><img src="img/vitals-autoencoder.png" style="width:60.0%" /></p>
    </figure>
    <p>Due to the non-randomized nature of real-world data, prognostic
      factors need to be balanced, which is often done by propensity scores
      (PSs). This study aimed to investigate whether autoencoders, which are
      unsupervised deep learning architectures, might be leveraged to compute
    PS.</p>
    <p>Presenter: Chamika Porage</p>
    <h2>Past meetings</h2>
    <h3>2023-12-07 – Playing Atari with Deep Reinforcement Learning</h3>
    <figure>
      <p><img src="img/atari.png" style="width:60.0%" /></p>
    </figure>
    <p>We present the first deep learning model to successfully learn
      control policies directly from high-dimensional sensory input using
      reinforcement learning. The model is a convolutional neural network,
      trained with a variant of Q-learning, whose input is raw pixels and
      whose output is a value function estimating future rewards. We apply our
      method to seven Atari 2600 games from the Arcade Learning Environment,
      with no adjustment of the architecture or learning algorithm. We find
      that it outperforms all previous approaches on six of the games and
    surpasses a human expert on three of them.</p>
    <p>Presenter: Andreas Östling</p>
    <h3>2023-10-12 – Is BERT Robust to Label Noise? <a href="#zhu2022bert"
    class="ref">[zhu2022bert]</a></h3>
    <figure>
      <p><img src="img/bert-label-noise.png" style="width:60.0%" /></p>
    </figure>
    <p>Abstract: Incorrect labels in training data occur when human
      annotators make mistakes or when the data is generated via weak or
      distant supervision. It has been shown that complex noise-handling
      techniques - by modeling, cleaning or filtering the noisy instances -
      are required to prevent models from fitting this label noise. However,
      we show in this work that, for text classification tasks with modern NLP
      models like BERT, over a variety of noise types, existing noisehandling
      methods do not always improve its performance, and may even deteriorate
      it, suggesting the need for further investigation. We also back our
    observations with a comprehensive analysis.</p>
    <p>Presenter: Hannes Waldetoft</p>
    <h3>2023-09-14 – Active Testing: Sample–Efficient Model Evaluation <a
    href="#kossen2021active" class="ref">[kossen2021active]</a></h3>
    <figure>
      <p><img src="img/active-testing.png" style="width:60.0%" /></p>
    </figure>
    <p>Abstract: We introduce a new framework for sample-efficient model
      evaluation that we call active testing. While approaches like active
      learning reduce the number of labels needed for model training, existing
      literature largely ignores the cost of labeling test data, typically
      unrealistically assuming large test sets for model evaluation. This
      creates a disconnect to real applications, where test labels are
      important and just as expensive, eg for optimizing hyperparameters.
      Active testing addresses this by carefully selecting the test points to
      label, ensuring model evaluation is sample-efficient. To this end, we
      derive theoretically-grounded and intuitive acquisition strategies that
      are specifically tailored to the goals of active testing, noting these
      are distinct to those of active learning. As actively selecting labels
      introduces a bias; we further show how to remove this bias while
      reducing the variance of the estimator at the same time. Active testing
      is easy to implement and can be applied to any supervised machine
      learning method. We demonstrate its effectiveness on models including
      WideResNets and Gaussian processes on datasets including Fashion-MNIST
    and CIFAR-100.</p>
    <p>Presenter: Väinö Yrjänäinen</p>
    <h3>2023-06-08 – Using natural language and program abstractions to
    instill human inductive biases in machines <a href="#kumar2022using"
    class="ref">[kumar2022using]</a></h3>
    <figure>
      <p><img src="img/human-biases.png" style="width:90.0%" /></p>
    </figure>
    <p>Abstract: Strong inductive biases give humans the ability to quickly
      learn to perform a variety of tasks. Although meta-learning is a method
      to endow neural networks with useful inductive biases, agents trained by
      meta-learning may sometimes acquire very different strategies from
      humans. We show that co-training these agents on predicting
      representations from natural language task descriptions and programs
      induced to generate such tasks guides them toward more human-like
      inductive biases. Human-generated language descriptions and program
      induction models that add new learned primitives both contain abstract
      concepts that can compress description length. Co-training on these
      representations result in more human-like behavior in downstream
      meta-reinforcement learning agents than less abstract controls
      (synthetic language descriptions, program induction without learned
      primitives), suggesting that the abstraction supported by these
    representations is key.</p>
    <p>Presenter: Isac Boström</p>
    <h3>2023-05-04 – Forecasting the movements of Bitcoin prices: an
    application of machine learning algorithms <a
      href="#pabucccu2023forecasting"
    class="ref">[pabucccu2023forecasting]</a></h3>
    <p>Abstract: Cryptocurrencies, such as Bitcoin, are one of the most
      controversial and complex technological innovations in today’s financial
      system. This study aims to forecast the movements of Bitcoin prices at a
      high degree of accuracy. To this aim, four different Machine Learning
      (ML) algorithms are applied, namely, the Support Vector Machines (SVM),
      the Artificial Neural Network (ANN), the Naive Bayes (NB) and the Random
      Forest (RF) besides the logistic regression (LR) as a benchmark model.
      In order to test these algorithms, besides existing continuous dataset,
      discrete dataset was also created and used. For the evaluations of
      algorithm performances, the F statistic, accuracy statistic, the Mean
      Absolute Error (MAE), the Root Mean Square Error (RMSE) and the Root
      Absolute Error (RAE) metrics were used. The t test was used to compare
      the performances of the SVM, ANN, NB and RF with the performance of the
      LR. Empirical findings reveal that, while the RF has the highest
      forecasting performance in the continuous dataset, the NB has the
      lowest. On the other hand, while the ANN has the highest and the NB the
      lowest performance in the discrete dataset. Furthermore, the discrete
      dataset improves the overall forecasting performance in all algorithms
    (models) estimated.</p>
    <p>Presenter: Sahika Gökmen</p>
  </body>
</html>